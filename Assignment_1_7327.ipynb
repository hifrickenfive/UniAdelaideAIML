{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AKoVenVVgFfe"
   },
   "source": [
    "## COMP SCI 7327 Concepts in Artificial Intelligence and Machine Learning -- Assignment 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kYzOUGXEgu_K"
   },
   "source": [
    "# Task 1： Explain the basic concepts (5 marks)\n",
    "\n",
    "1. ROC curve is a graphical plot that illustrates the diagnostic ability of a binary classifier system as its discrimination threshold is varied. Please explain how the ROC curve works in the binary classification (1 mark).\n",
    "\n",
    "2. Please describe what is cross-entropy and under what circumstances cross-entropy can be used (2 marks)?\n",
    "\n",
    "4. Please explain what are the similarities and differences of L1 loss and MSE loss in K-Nearest Neighbor training (2 marks)?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ROC curves show the trade off between false-positives and false-negatives of a classification model as a function of varying the discrimination threshold.\n",
    "2. Cross entropy. Surprise is the inverse of probability. Surprise is the log inverse of the probability of an event. Entropy is the expected value of the surprise.\n",
    "3. L1 loss and MSE loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "esyKtc4Sl0on"
   },
   "source": [
    "# Task 2 ：Python programming (8 marks)\n",
    "\n",
    "1. Given a list of numbers: num=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], write python code that finds all odd numbers in a list and returns a new list that contains all the odd numbers (2 marks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_odd_num(numbers):\n",
    "    odd_numbers = [num for num in numbers if num % 2 > 0]\n",
    "    return odd_numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xtRQVLwFl-Tn"
   },
   "source": [
    "2. The “carry” means if the summation of one digital position is greater than 10, an another 1 will be added to the next position. Please write python code to count the number of the “carry” operations. For example, 123+456 has no \"carry\" as neither of 3+6，2+5, 1+4 is greater than 10. Some other examples are as below (3 marks):\n",
    "\n",
    "> **Example 1:**\n",
    "\n",
    "> Input: \n",
    "> 123+456\n",
    "\n",
    "> Output:\n",
    "> No carry operation.\n",
    "\n",
    "> **Example 2:**\n",
    "\n",
    "> Input: \n",
    "> 555+555\n",
    "\n",
    "> Output:\n",
    "> 3 carry operations.\n",
    "\n",
    "> **Example 3:**\n",
    "\n",
    "> Input: \n",
    "> 123+594\n",
    "\n",
    "> Output:\n",
    "> 1 carry operation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countCarries(number_a: int, number_b: int) -> int:\n",
    "    \"\"\"Count the carries.\n",
    "    \n",
    "    Args:\n",
    "        number_a (int) \n",
    "        number_b (int) \n",
    "    Returns:\n",
    "        num_carries (int)\n",
    "\n",
    "    Assumptions:\n",
    "    1. Addition only.\n",
    "    2. Negative numbers excluded.\n",
    "    \"\"\"\n",
    "    num_carries = 0\n",
    "    number_c = number_a + number_b\n",
    "\n",
    "    digits_a = [int(a) for a in str(abs(number_a))]\n",
    "    digits_b = [int(b) for b in str(abs(number_b))]\n",
    "    digits_c = [int(c) for c in str(abs(number_c))]\n",
    "\n",
    "    digits_a.reverse()\n",
    "    digits_b.reverse()\n",
    "    digits_c.reverse()\n",
    "\n",
    "    num_least_digits = min(len(digits_a), len(digits_b))\n",
    "\n",
    "    for i in range(num_least_digits):\n",
    "        if digits_c[i] < digits_b[i] + digits_a[i]:\n",
    "            num_carries += 1\n",
    "\n",
    "    return num_carries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FNo6I-vMmFRR"
   },
   "source": [
    "3. Roman numerals are represented by seven different symbols: I (=1) , V (=5), X(=10), L (=50), C(=100), D (=500) and M(=1000). For example, 2 is written as 'II' in Roman numeral, just two 'I' added together. The number 27 is written as XXVII, which is XX + V + II. Your task is to write a Python code that recognizes the roman numbers. The input and output should be in the format as shown below (3 marks):\n",
    "\n",
    ">**Example 1:**\n",
    "\n",
    ">Input: s = \"III\"\n",
    "\n",
    ">Output: 3\n",
    "\n",
    ">**Example 2:**\n",
    "\n",
    ">Input: s = \"LVIII\"\n",
    "\n",
    ">Output: 58\n",
    "\n",
    ">**Example 3:**\n",
    "\n",
    ">Input: s = \"MCMXCIV\"\n",
    "\n",
    ">Output: 1994\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def convert_to_numbers(roman_string: str) -> int:\n",
    "    \"\"\"Convert roman numerals to numbers.\n",
    "\n",
    "    Args:\n",
    "        roman_string (string) \n",
    "\n",
    "    Returns:\n",
    "        number (int)\n",
    "    \"\"\"\n",
    "    rome2num = {'I': 1, 'V': 5, 'X': 10,\n",
    "                'L': 50, 'C': 100, 'D': 500, 'M': 1000}\n",
    "    sum = 0\n",
    "    previous_num = math.inf\n",
    "\n",
    "    for index, char in enumerate(roman_string):\n",
    "        current_num = rome2num[char]\n",
    "        if previous_num < current_num:\n",
    "            sum -= 2*previous_num\n",
    "            sum += current_num\n",
    "        else:\n",
    "            sum += current_num\n",
    "            previous_num = current_num\n",
    "\n",
    "    return sum\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TjTd8XaYnFLb"
   },
   "source": [
    "# Task 3 : Algorithm Programming (7 marks)\n",
    "\n",
    "1. Download the MNIST dataset and split the dataset into a training set (70% of the data), validation set (10% of the data) and testing set (20% of the data) (1 Mark).\n",
    "\n",
    "2. Build a classifier with three convolutional layers with pyTorch 1.2.0 (cpu version) (2 Marks).\n",
    "\n",
    "3. Successfully train the classifier and record the accuracy on the testing set. Please note that you will need to use all the three subsets you got in 1. (2 Marks).\n",
    "4. Please draw the loss curves and accuracy curves for both the training and validation set. You have to use Matplotlib to draw the figure.(2 Marks).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, svm, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Get MNIST via sklearn\n",
    "X, y = datasets.fetch_openml(\"mnist_784\", version=1, return_X_y=True, as_frame=False)\n",
    "# X is the data set and y are its labels. If return_X_y=False, then type is sklearn 'Bunch', an extension of dictionaries.\n",
    "\n",
    "# Split the data\n",
    "X_train, X_delta, y_train, y_delta = train_test_split(X, y, train_size= 0.7, test_size=0.3)\n",
    "X_validation, X_test, y_validation, y_test = train_test_split(X_delta, y_delta, train_size= 1/3, test_size=2/3)\n",
    "\n",
    "# Demonstrate that the dataset has been split: 70% training, 10% validation, 20% training\n",
    "print(f'validation_set: {len(X_validation)}, test_set: {len(X_test)}, training_set: {len(X_train)}')\n",
    "print(f'validation_set: {len(X_validation)/len(X)}, test_set: {len(X_test)/len(X)}, training_set: {len(X_train)/len(X)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is now 70000 data instances in all_data.\n",
      "There is now 49000 data instances in train_data_resliced (70% of all_data).\n",
      "There is now 14000 data instances in test_data_resliced (20% of all_data).\n",
      "There is now 7000 data instances in validation_data (10% of all_data).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import datasets\n",
    "\n",
    "train_data = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = True,                         \n",
    "    transform = ToTensor(), \n",
    "    download = True,            \n",
    ")\n",
    "test_data = datasets.MNIST(\n",
    "    root = 'data', \n",
    "    train = False, \n",
    "    transform = ToTensor()\n",
    ")\n",
    "\n",
    "# Concatenate MNIST training and test set\n",
    "all_data = torch.utils.data.ConcatDataset([train_data, test_data])\n",
    "print(f'There is now {len(all_data)} data instances in all_data.')\n",
    "\n",
    "# Recut all_data: 70% training, 20% test, 10% validation.\n",
    "# Lesson leartn: can't naively slice pytorch data class. Use Subset method.\n",
    "idx_train = int(len(all_data)*0.7)\n",
    "idx_test = idx_train + int(len(all_data)*0.2)\n",
    "idx_validation = len(all_data)\n",
    "\n",
    "train_indices = list(range(0, idx_train))\n",
    "train_data_resliced = torch.utils.data.Subset(all_data, train_indices)\n",
    "print(f'There is now {len(train_data_resliced)} data instances in train_data_resliced (70% of all_data).')\n",
    "\n",
    "test_indices = list(range(idx_train, idx_test))\n",
    "test_data_resliced = torch.utils.data.Subset(all_data, test_indices)\n",
    "print(f'There is now {len(test_data_resliced)} data instances in test_data_resliced (20% of all_data).')\n",
    "\n",
    "validation_indices = list(range(idx_test, idx_validation))\n",
    "validation_data = torch.utils.data.Subset(all_data, validation_indices)\n",
    "print(f'There is now {len(validation_data)} data instances in validation_data (10% of all_data).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten()\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=64, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "from torch import optim\n",
    "\n",
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten() # converts 2D arrays into one contiguous array.\n",
    "        self.linear_relu_stack = nn.Sequential( \n",
    "            nn.Linear(28*28, 64), # args for CNN: input channels, output channels, kernel_size\n",
    "            nn.ReLU(), # an activation layer that introduces non-linearities to the linear model\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)\n",
    "\n",
    "# Define optimiser\n",
    "optimiser = optim.SGD(model.parameters(), lr=1e-2)\n",
    "\n",
    "# Define loss function\n",
    "# This defines how the optimiser changes the NN parameters\n",
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data into Pytorch loader\n",
    "train_loader = DataLoader(train_data_resliced, batch_size=32)\n",
    "validation_loader = DataLoader(validation_data, batch_size=32)\n",
    "test_loader = DataLoader(test_data_resliced, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, train_loss: 0.27\n",
      "Epoch 5, validation_loss: 0.26\n"
     ]
    }
   ],
   "source": [
    "# Train the model and validation loops\n",
    "\n",
    "# References\n",
    "# PyTorch Lightning: https://www.youtube.com/watch?v=OMDn66kM9Qc&ab_channel=PyTorchLightning\n",
    "\n",
    "# Train the model\n",
    "nb_epochs = 5\n",
    "for epoch in range(nb_epochs):\n",
    "    loss = list()\n",
    "    for batch in train_loader:\n",
    "        x, y = batch # x is image and y is label\n",
    "\n",
    "        # Create matrix x, x: batch size x 1 channel x 28px x 28px\n",
    "        num_rows = x.size(0)\n",
    "        x = x.view(num_rows, -1) # Creates a matrix whose num_rows is batch size, num_columns = 28x28\n",
    "\n",
    "        # Step 1: forward\n",
    "        logits = model(x) \n",
    "        \n",
    "        # Step 2: Compute the objective function\n",
    "        J = loss_function(logits, y)\n",
    "\n",
    "        # Step 3: Clean gradients\n",
    "        model.zero_grad() # Equivalent to optimser.zero_grad() or params.grad._zero()\n",
    "\n",
    "        # Step 4: Accumulate the partial derivatives of J wrt params\n",
    "        J.backward() # Equivalent to params.grad._sum(dJ/dparams)\n",
    "\n",
    "        # Step 5: Step in the oppostie direction of the gradient\n",
    "        optimiser.step() \n",
    "\n",
    "        loss.append(J.item())\n",
    "\n",
    "print(f'Epoch {epoch +1}, train_loss: {torch.tensor(loss).mean():.2f}')\n",
    "\n",
    "# Validate model\n",
    "losses = list()\n",
    "for batch in validation_loader:\n",
    "    x, y = batch # x is image and y is label\n",
    "\n",
    "    # Create matrix x, x: batch size x 1 channel x 28px x 28px\n",
    "    num_rows = x.size(0)\n",
    "    x = x.view(num_rows, -1) # Creates a matrix whose num_rows is batch size, num_columns = 28x28\n",
    "\n",
    "    # Step 1: forward\n",
    "    with torch.no_grad():\n",
    "        logits = model(x)\n",
    "    \n",
    "    # Step 2: Compute the objective function\n",
    "    J = loss_function(logits, y)\n",
    "\n",
    "    loss.append(J.item())\n",
    "\n",
    "print(f'Epoch {epoch +1}, validation_loss: {torch.tensor(loss).mean():.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Assignment_1_7327.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
